version: '3.8'

services:
  # inference-server:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: inference-server
  #   environment:
  #     - TRANSFORMERS_CACHE=/models/cache
  #   volumes:
  #     - ./models:/models
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/docs"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

  sentiment-sentiment:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5001:5001"
    environment:
      - PREDICT_API_URL=http://0.0.0.0:8008/predict
    command: python socket_server.py
    restart: always
